<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>IntellJ学习（一）：Debug</title>
      <link href="/2022/05/28/debug/"/>
      <url>/2022/05/28/debug/</url>
      
        <content type="html"><![CDATA[<h1 id="程序调试标准动作"><a href="#程序调试标准动作" class="headerlink" title="程序调试标准动作"></a>程序调试标准动作</h1><ul><li>查看变量的值，展开实例看内部成员变量的值</li><li>Step Over(F8)：从断点处开始，逐行执行代码，不进入方法。</li><li>Step Into(F7): 从断点处开始，逐行执行代码，如果遇到方法，会进入方法，但是只能进入自定义方法，不会进入官方类库的方法。</li><li>Force Step Into (Alt Shift F7): 从断点处开始，逐行执行代码，如果遇到方法，会进入方法，适用于所有方法。</li><li>Step Out(Shift F8)：继续执行直到遇到下一个断点或者方法结束</li><li>Resume(F9)：继续执行直到遇到下一个断点或者程序结束</li><li>执行任意代码Evaluate Expression：在对话框输入代码，直接执行看结果值</li><li>条件断点：给断点设置条件，只有满足条件时，程序才会在该断点停住</li></ul>]]></content>
      
      
      <categories>
          
          <category> tools </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Maven学习（一）：基本概念</title>
      <link href="/2022/05/28/fuck-maven/"/>
      <url>/2022/05/28/fuck-maven/</url>
      
        <content type="html"><![CDATA[<h1 id="jar-包的仓库"><a href="#jar-包的仓库" class="headerlink" title="jar 包的仓库"></a>jar 包的仓库</h1><ul><li>maven 有两部分，首先是服务器端，叫做maven repo，或者nexusserver。 它将所有的 jar 包放在一个仓库里。</li><li>所有 jar 包都发布到这个仓库。需要用到某个jar 包，就去这个仓库下载。</li><li>仓库里每个 jar 包，都有唯一的 id。这个id 是由三部分组成的：groupid，artifact id 和 version。<br>group id是发布jar包的组织名称，artifact id是jar包的名称，version是版本号。<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scalanlp<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>breeze_2.10<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span> <span class="comment">&lt;!-- or 2.11 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.10<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li>为了避免每次都从服务器下载 artifact（jar包），maven会把下载好的artifact 放在本地的文件夹，这个就叫做local repo, local repor地址：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Users/suwenjin/.m2</span><br></pre></td></tr></table></figure></li></ul><h1 id="maven客户端"><a href="#maven客户端" class="headerlink" title="maven客户端"></a>maven客户端</h1><ul><li>如果一个项目 ChatRoom 依赖某个 jar 包，比如guava，那么就把guava的 id 加入到自己的依赖里，maven 客户端就可以通过id找到并使用guava 了。</li><li>同时，maven 的依赖是传递的。如果使用maven 发布这个jar包到maven repo，maven 还会记住ChatRoom的jar 包依赖于guava。如果有别的项目依赖 ChatRoom，那么它将自动依赖guava，无需再次声明。</li></ul><h1 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h1><ul><li><p>maven 构建中的几个主要的 phase：clean compile test package install site</p><ol><li>clean: 清楚maven之前生成的class、jar等文件</li><li>compile:将java文件编译成class文件</li><li>test: 执行测试用例</li><li>package: 将项目打成jar包</li><li>install: 将jar包安装到local repo</li><li>site: 生成项目相关信息的网站</li></ol></li><li><p>其他命令：</p><ol><li>mvn dependency:resolve 打印出已解决依赖的列表</li><li>mvn dependency:tree 打印整个依赖树</li><li>mvn install -X 想要查看完整的依赖踪迹，包含那些因为冲突或者其它原因而被拒绝引入的构件，打开 Maven 的调试标记运行</li></ol></li></ul><h1 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h1><p><a href="https://www.jianshu.com/p/c5d84c2c7fc8">Maven的依赖(1) 之 依赖的作用域scope</a></p><h1 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h1><ul><li>插件是什么：maven 其实是一套框架，所有的具体任务都是插件完成的。除了核心的编译打包插件，还有非常多的别的目的的插件。</li><li>打出 fatjar 的插件</li></ul>]]></content>
      
      
      <categories>
          
          <category> maven </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark学习（四）：dataframe构造structType</title>
      <link href="/2022/05/25/spark-sql-convent-struct-type/"/>
      <url>/2022/05/25/spark-sql-convent-struct-type/</url>
      
        <content type="html"><![CDATA[<h1 id="需求背景"><a href="#需求背景" class="headerlink" title="需求背景"></a>需求背景</h1><p>为满足业务系统能够像解析mongo数据一样解析大数据产出的数据，我们绝对将多个字段的多行数据处理到一个字段中。<br>如下表中的数据所示，一组task和serid有多个sku，一个sku下又有多个location,我们需要将这些数据处理成嵌套形式的Schema。</p><h1 id="示例数据"><a href="#示例数据" class="headerlink" title="示例数据"></a>示例数据</h1><figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">+-------+---------+------+--------+----+----+----+----+</span><br><span class="line">|task<span class="emphasis">_id|serial_</span>id|sku<span class="emphasis">_id|sku_</span>name|xMax|xMin|Ymin|Ymax|</span><br><span class="line">+-------+---------+------+--------+----+----+----+----+</span><br><span class="line">|      a|        1|     1|    啤酒|   0|   0|   0|   0|</span><br><span class="line">|      a|        1|     1|    啤酒|   0|   0|   0|   1|</span><br><span class="line">|      a|        1|     1|    啤酒|   0|   0|   1|   0|</span><br><span class="line">|      a|        1|     1|    啤酒|   0|   0|   1|   1|</span><br><span class="line">|      a|        1|     2|    可乐|   0|   1|   0|   0|</span><br><span class="line">|      a|        1|     2|    可乐|   0|   1|   0|   1|</span><br><span class="line">|      a|        1|     2|    可乐|   0|   1|   1|   0|</span><br><span class="line">|      a|        1|     2|    可乐|   0|   1|   1|   1|</span><br><span class="line">+-------+---------+------+--------+----+----+----+----+</span><br></pre></td></tr></table></figure><h1 id="示例数据Schema"><a href="#示例数据Schema" class="headerlink" title="示例数据Schema"></a>示例数据Schema</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line">|-- task_id: string (nullable = true)</span><br><span class="line">|-- serial_id: integer (nullable = true)</span><br><span class="line">|-- sku_id: integer (nullable = true)</span><br><span class="line">|-- sku_name: string (nullable = true)</span><br><span class="line">|-- xMax: integer (nullable = true)</span><br><span class="line">|-- xMin: integer (nullable = true)</span><br><span class="line">|-- Ymin: integer (nullable = true)</span><br><span class="line">|-- Ymax: integer (nullable = true)</span><br></pre></td></tr></table></figure><h1 id="目标数据Schema"><a href="#目标数据Schema" class="headerlink" title="目标数据Schema"></a>目标数据Schema</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">root</span><br><span class="line">|-- task_id: string (nullable = <span class="literal">true</span>)</span><br><span class="line">|-- serial_id: integer (nullable = <span class="literal">true</span>)</span><br><span class="line">|-- processed_results: array (nullable = <span class="literal">false</span>)</span><br><span class="line">|    |-- element: struct (containsNull = <span class="literal">false</span>)</span><br><span class="line">|    |    |-- bounding_box: struct (nullable = <span class="literal">false</span>)</span><br><span class="line">|    |    |    |-- top_left: struct (nullable = <span class="literal">false</span>)</span><br><span class="line">|    |    |    |    |-- <span class="type">Xmin</span>: integer (nullable = <span class="literal">true</span>)</span><br><span class="line">|    |    |    |    |-- <span class="type">Ymin</span>: integer (nullable = <span class="literal">true</span>)</span><br><span class="line">|    |    |    |-- bottom_right: struct (nullable = <span class="literal">false</span>)</span><br><span class="line">|    |    |    |    |-- <span class="type">Xmax</span>: integer (nullable = <span class="literal">true</span>)</span><br><span class="line">|    |    |    |    |-- <span class="type">Ymax</span>: integer (nullable = <span class="literal">true</span>)</span><br><span class="line">|    |    |-- sku_lists: struct (nullable = <span class="literal">false</span>)</span><br><span class="line">|    |    |    |-- sku_id: integer (nullable = <span class="literal">true</span>)</span><br><span class="line">|    |    |    |-- sku_name: string (nullable = <span class="literal">true</span>)</span><br></pre></td></tr></table></figure><h1 id="关键代码"><a href="#关键代码" class="headerlink" title="关键代码"></a>关键代码</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> structDF = df.groupBy($<span class="string">&quot;task_id&quot;</span>, $<span class="string">&quot;serial_id&quot;</span>)</span><br><span class="line">   .agg(</span><br><span class="line">     collect_list(</span><br><span class="line">       struct(</span><br><span class="line">         struct(struct($<span class="string">&quot;Xmin&quot;</span>, $<span class="string">&quot;Ymin&quot;</span>).as(<span class="string">&quot;top_left&quot;</span>), struct($<span class="string">&quot;Xmax&quot;</span>, $<span class="string">&quot;Ymax&quot;</span>).as(<span class="string">&quot;bottom_right&quot;</span>)).as(<span class="string">&quot;bounding_box&quot;</span>),</span><br><span class="line">         struct($<span class="string">&quot;sku_id&quot;</span>, $<span class="string">&quot;sku_name&quot;</span>).as(<span class="string">&quot;sku_lists&quot;</span>)</span><br><span class="line">       )</span><br><span class="line">     ).as(<span class="string">&quot;processed_results&quot;</span>)</span><br><span class="line">   )</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> spark-sql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark学习（三）：Watermark</title>
      <link href="/2022/05/25/spark-structured-streaming-example/"/>
      <url>/2022/05/25/spark-structured-streaming-example/</url>
      
        <content type="html"><![CDATA[<h1 id="程序配置"><a href="#程序配置" class="headerlink" title="程序配置"></a>程序配置</h1><p>窗口大小：10 minutes<br>watermark大小：10 minutes<br>滑动时间：5 minutes<br>触发方式：default, 尽快触发, 自由切割</p><h1 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h1><table><thead><tr><th>event_time</th><th>word</th><th>isCounted</th><th>watermark</th><th>window of watermark</th></tr></thead><tbody><tr><td>2022-05-25 09:45:00</td><td>a</td><td>count</td><td>2022-09-25 09:35:00</td><td>2022-09-25 09:30:00 ~ 2022-09-25 09:40:00</td></tr><tr><td>2022-05-25 09:25:00</td><td>b</td><td>not count</td><td>2022-09-25 09:35:00</td><td>2022-09-25 09:30:00 ~ 2022-09-25 09:40:00</td></tr><tr><td>2022-05-25 09:29:59</td><td>b</td><td>not count</td><td>2022-09-25 09:35:00</td><td>2022-09-25 09:30:00 ~ 2022-09-25 09:40:00</td></tr><tr><td>2022-05-25 09:30:00</td><td>b</td><td>count</td><td>2022-09-25 09:35:00</td><td>2022-09-25 09:30:00 ~ 2022-09-25 09:40:00</td></tr><tr><td>2022-05-25 09:35:00</td><td>b</td><td>count</td><td>2022-09-25 09:35:00</td><td>2022-09-25 09:30:00 ~ 2022-09-25 09:40:00</td></tr><tr><td>2022-05-25 09:50:00</td><td>c</td><td>count</td><td>2022-09-25 09:40:00</td><td>2022-09-25 09:35:00 ~ 2022-09-25 09:45:00</td></tr><tr><td>2022-05-25 09:30:00</td><td>d</td><td>not count</td><td>2022-09-25 09:40:00</td><td>2022-09-25 09:35:00 ~ 2022-09-25 09:45:00</td></tr><tr><td>2022-05-25 09:34:00</td><td>d</td><td>not count</td><td>2022-09-25 09:40:00</td><td>2022-09-25 09:35:00 ~ 2022-09-25 09:45:00</td></tr><tr><td>2022-05-25 09:35:00</td><td>d</td><td>count</td><td>2022-09-25 09:40:00</td><td>2022-09-25 09:35:00 ~ 2022-09-25 09:45:00</td></tr><tr><td>2022-05-25 09:35:01</td><td>d</td><td>count</td><td>2022-09-25 09:40:00</td><td>2022-09-25 09:35:00 ~ 2022-09-25 09:45:00</td></tr></tbody></table><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><ol><li>如果数据的event_time &gt;&#x3D; watermark所在最近的一个window的开始时间，就会被处理。而不是&gt;&#x3D;watermark的时间。</li><li>watermark属于多个窗口时，用于比较的是时间最靠后的一个窗口。比如2022-09-25 09:35:00所在窗口是09：25～09：35，09：30～09：40，spark是用第二个窗口来比较event_time。</li></ol><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  <span class="comment">// 设置需要监听的本机地址与端口号</span></span><br><span class="line">  <span class="keyword">val</span> host: <span class="type">String</span> = <span class="string">&quot;127.0.0.1&quot;</span></span><br><span class="line">  <span class="keyword">val</span> port: <span class="type">String</span> = <span class="string">&quot;9999&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//  nc -lk 9999</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 从监听地址创建DataFrame</span></span><br><span class="line">  <span class="keyword">var</span> df: <span class="type">DataFrame</span> = spark.readStream</span><br><span class="line">    .format(<span class="string">&quot;socket&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;host&quot;</span>, host)</span><br><span class="line">    .option(<span class="string">&quot;port&quot;</span>, port)</span><br><span class="line">    .load()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 使用DataFrame API完成Word Count计算</span></span><br><span class="line"><span class="comment">   * */</span></span><br><span class="line">  <span class="comment">// 首先把接收到的字符串，以空格为分隔符做拆分，得到单词数组words</span></span><br><span class="line">  <span class="keyword">val</span> countDf = df.withColumn(<span class="string">&quot;inputs&quot;</span>, split(df(<span class="string">&quot;value&quot;</span>), <span class="string">&quot;,&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;event_time&quot;</span>, element_at(col(<span class="string">&quot;inputs&quot;</span>), <span class="number">1</span>).cast(<span class="string">&quot;timestamp&quot;</span>))</span><br><span class="line">    .withColumn(<span class="string">&quot;word&quot;</span>, element_at(col(<span class="string">&quot;inputs&quot;</span>), <span class="number">2</span>))</span><br><span class="line">    <span class="comment">// 根据event_time计算watermark</span></span><br><span class="line">    .withWatermark(<span class="string">&quot;event_time&quot;</span>, <span class="string">&quot;10 minutes&quot;</span>)</span><br><span class="line">    <span class="comment">// 10 mins windows, sliding every 5mins</span></span><br><span class="line">    .groupBy(window(col(<span class="string">&quot;event_time&quot;</span>), <span class="string">&quot;10 minutes&quot;</span>, <span class="string">&quot;5 minutes&quot;</span>), col(<span class="string">&quot;word&quot;</span>))</span><br><span class="line">    .count()</span><br><span class="line"></span><br><span class="line">  countDf.writeStream</span><br><span class="line">    .format(<span class="string">&quot;console&quot;</span>) <span class="comment">// 指定Sink为终端（Console）</span></span><br><span class="line">    .option(<span class="string">&quot;truncate&quot;</span>, <span class="literal">false</span>) <span class="comment">// 指定输出选项,“truncate”选项，用来表明输出内容是否需要截断。</span></span><br><span class="line"><span class="comment">//     .outputMode(&quot;complete&quot;)</span></span><br><span class="line">    .outputMode(<span class="string">&quot;update&quot;</span>)</span><br><span class="line">    .start() <span class="comment">// 启动流处理应用</span></span><br><span class="line">    .awaitTermination() <span class="comment">// 等待中断指令</span></span><br></pre></td></tr></table></figure><h1 id="Github"><a href="#Github" class="headerlink" title="Github"></a>Github</h1><p><a href="https://github.com/jwsmai/ScalaTools/blob/main/src/main/scala/spark/stream/WordCountWaterMarkWindowExample.scala">https://github.com/jwsmai/ScalaTools/blob/main/src/main/scala/spark/stream/WordCountWaterMarkWindowExample.scala</a></p>]]></content>
      
      
      <categories>
          
          <category> spark-structured-streaming </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 实时计算 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark学习（二）：窗口函数</title>
      <link href="/2022/05/24/spark-window-function/"/>
      <url>/2022/05/24/spark-window-function/</url>
      
        <content type="html"><![CDATA[<h1 id="Syntaxes"><a href="#Syntaxes" class="headerlink" title="Syntaxes"></a>Syntaxes</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.expressions.<span class="type">Window</span></span><br><span class="line"><span class="keyword">val</span> window = <span class="type">Window</span>.partitionBy(<span class="string">&quot;columnName&quot;</span>)</span><br><span class="line">df.withColumn(<span class="string">&quot;newColumn&quot;</span>, sum(<span class="string">&quot;xxx&quot;</span>).over(window))</span><br></pre></td></tr></table></figure><p>按照上面的写法就是根据某一列开窗，<strong>当我们不需要对某一列开窗的时候而对所有行进行sum，我们不对<code>.over</code>函数传参即可</strong>。</p><h1 id="Practics"><a href="#Practics" class="headerlink" title="Practics"></a>Practics</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Salary</span>(<span class="params">depName: <span class="type">String</span>, empNo: <span class="type">Long</span>, salary: <span class="type">Long</span></span>)</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> empsalary = <span class="type">Seq</span>(</span><br><span class="line">    <span class="type">Salary</span>(<span class="string">&quot;sales&quot;</span>, <span class="number">1</span>, <span class="number">50</span>),</span><br><span class="line">    <span class="type">Salary</span>(<span class="string">&quot;personnel&quot;</span>, <span class="number">2</span>, <span class="number">39</span>),</span><br><span class="line">    <span class="type">Salary</span>(<span class="string">&quot;sales&quot;</span>, <span class="number">3</span>, <span class="number">48</span>),</span><br><span class="line">    <span class="type">Salary</span>(<span class="string">&quot;personnel&quot;</span>, <span class="number">5</span>, <span class="number">35</span>),</span><br><span class="line">    <span class="type">Salary</span>(<span class="string">&quot;develop&quot;</span>, <span class="number">7</span>, <span class="number">42</span>),</span><br><span class="line">    <span class="type">Salary</span>(<span class="string">&quot;develop&quot;</span>, <span class="number">11</span>, <span class="number">52</span>)).toDF()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 窗口函数</span></span><br><span class="line">  <span class="keyword">val</span> byDepName = <span class="type">Window</span>.partitionBy(<span class="string">&quot;depName&quot;</span>)</span><br><span class="line">  empsalary.withColumn(<span class="string">&quot;depSalSum&quot;</span>, sum(<span class="string">&quot;salary&quot;</span>).over(byDepName))</span><br><span class="line">    .withColumn(<span class="string">&quot;depSalMax&quot;</span>, max(<span class="string">&quot;salary&quot;</span>).over(byDepName))</span><br><span class="line">    .withColumn(<span class="string">&quot;depSalMin&quot;</span>, min(<span class="string">&quot;salary&quot;</span>).over(byDepName))</span><br><span class="line">    .withColumn(<span class="string">&quot;AllSum&quot;</span>, sum(<span class="string">&quot;salary&quot;</span>).over()) <span class="comment">// 直接sum所有列</span></span><br><span class="line">    .show()</span><br></pre></td></tr></table></figure><h1 id="Github地址"><a href="#Github地址" class="headerlink" title="Github地址"></a>Github地址</h1><p><a href="https://github.com/jwsmai/ScalaTools/blob/main/src/main/scala/spark/sql/WindowFunctionExample.scala">https://github.com/jwsmai/ScalaTools/blob/main/src/main/scala/spark/sql/WindowFunctionExample.scala</a></p><h1 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h1><p><a href="https://medium.com/expedia-group-tech/deep-dive-into-apache-spark-window-functions-7b4e39ad3c86">https://medium.com/expedia-group-tech/deep-dive-into-apache-spark-window-functions-7b4e39ad3c86</a></p>]]></content>
      
      
      <categories>
          
          <category> spark-sql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 窗口函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark学习（一）：filter算子</title>
      <link href="/2022/05/24/spark-sql-filter/"/>
      <url>/2022/05/24/spark-sql-filter/</url>
      
        <content type="html"><![CDATA[<h1 id="Syntaxes"><a href="#Syntaxes" class="headerlink" title="Syntaxes"></a>Syntaxes</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">filter(condition: <span class="type">Column</span>): <span class="type">Dataset</span>[<span class="type">T</span>] <span class="comment">// 对Column进行条件过滤</span></span><br><span class="line">filter(conditionExpr: <span class="type">String</span>): <span class="type">Dataset</span>[<span class="type">T</span>] <span class="comment">//using SQL expression </span></span><br><span class="line">filter(func: <span class="type">T</span> =&gt; <span class="type">Boolean</span>): <span class="type">Dataset</span>[<span class="type">T</span>]</span><br><span class="line">filter(func: <span class="type">FilterFunction</span>[<span class="type">T</span>]): <span class="type">Dataset</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure><h1 id="Practice"><a href="#Practice" class="headerlink" title="Practice"></a>Practice</h1><h3 id="filter-with-Column-condition"><a href="#filter-with-Column-condition" class="headerlink" title="filter() with Column condition"></a>filter() with Column condition</h3><p>用&#x3D;!&#x3D;表达not equal.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This import is needed to use the $-notation and &#x27;-notation</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">df1.filter(col(<span class="string">&quot;name&quot;</span>) === <span class="string">&quot;suwenjin&quot;</span>).show()</span><br><span class="line">df1.filter(df1(<span class="string">&quot;name&quot;</span>) === <span class="string">&quot;suwenjin&quot;</span>).show()</span><br><span class="line">df1.filter($<span class="string">&quot;name&quot;</span> === <span class="string">&quot;suwenjin&quot;</span>).show()</span><br><span class="line">df1.filter(&#x27;name === <span class="string">&quot;suwenjin&quot;</span>).show()</span><br><span class="line">df1.filter(&#x27;name =!= <span class="string">&quot;suwenjin&quot;</span>).show() <span class="comment">// not equal</span></span><br></pre></td></tr></table></figure><p>使用<code>$-notation</code>和<code>&#39;-notation</code>时需要导入<code>implicits</code></p><h3 id="filter-with-SQL-Expression"><a href="#filter-with-SQL-Expression" class="headerlink" title="filter() with SQL Expression"></a>filter() with SQL Expression</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df1.filter(<span class="string">&quot;name == &#x27;suwenjin&#x27;&quot;</span>).show()</span><br><span class="line">df1.filter(<span class="string">&quot;name = &#x27;suwenjin&#x27;&quot;</span>).show()</span><br></pre></td></tr></table></figure><p>sql表达式里可以使用”&#x3D;”或者”&#x3D;&#x3D;&#x3D;”来判断是否相等。</p><h3 id="Filter-with-Multiple-Conditions"><a href="#Filter-with-Multiple-Conditions" class="headerlink" title="Filter with Multiple Conditions"></a>Filter with Multiple Conditions</h3><p>AND(&amp;&amp;), OR(||), and NOT(!)</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df1.filter($<span class="string">&quot;name&quot;</span> === <span class="string">&quot;suwenjin&quot;</span> &amp;&amp; $<span class="string">&quot;age&quot;</span> === <span class="number">12</span>).show()</span><br><span class="line">df1.filter($<span class="string">&quot;name&quot;</span> === <span class="string">&quot;suwenjin&quot;</span> || $<span class="string">&quot;age&quot;</span> =!= <span class="number">12</span>).show()</span><br></pre></td></tr></table></figure><h1 id="Github地址"><a href="#Github地址" class="headerlink" title="Github地址"></a>Github地址</h1><p><a href="https://github.com/jwsmai/ScalaTools/blob/main/src/main/scala/spark/sql/DataframeFilterExample.scala">https://github.com/jwsmai/ScalaTools/blob/main/src/main/scala/spark/sql/DataframeFilterExample.scala</a></p>]]></content>
      
      
      <categories>
          
          <category> spark-sql </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark踩坑（一）：maven依赖冲突</title>
      <link href="/2022/05/23/fuck-sparksql/"/>
      <url>/2022/05/23/fuck-sparksql/</url>
      
        <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>原来项目中只有spark的maven依赖，新增flink依赖后，spark程序运行报错。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ Caused by: java.lang.ClassNotFoundException: com.esotericsoftware.kryo.pool.KryoFactory</span><br></pre></td></tr></table></figure><p>SparkSql原来依赖<code>com.esotericsoftware.kryo:kryo:jar:2.21</code>，但flink依赖中包含<code>com.esotericsoftware.kryo:kryo:jar:2.24.0</code>和<br><code>com.esotericsoftware.kryo:kryo:jar:2.21</code>， 在多版本同时存在的情况下，Java类加载器加载到了高版本的 kryo。由于高低版本不兼容，所以SparkSql报错。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.15.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h1><p>使用下面的命令排查冲突的依赖：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ mvn dependency:tree -Dverbose -Dincludes=com.esotericsoftware.kryo</span><br><span class="line"></span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ ScalaTools ---</span><br><span class="line">[INFO] groupId:ScalaTools:jar:1.0-SNAPSHOT</span><br><span class="line">[INFO] \- org.apache.flink:flink-clients:jar:1.15.0:compile</span><br><span class="line">[INFO]    +- org.apache.flink:flink-core:jar:1.15.0:compile</span><br><span class="line">[INFO]    |  \- com.esotericsoftware.kryo:kryo:jar:2.24.0:compile</span><br><span class="line">[INFO]    \- org.apache.flink:flink-java:jar:1.15.0:compile</span><br><span class="line">[INFO]       \- com.twitter:chill-java:jar:0.7.6:compile</span><br><span class="line">[INFO]          \- (com.esotericsoftware.kryo:kryo:jar:2.21:compile - omitted <span class="keyword">for</span> conflict with 2.24.0)</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p>从上面的执行结果中可以发现<code>org.apache.flink:flink-clients</code>下有两个版本的<code>com.esotericsoftware.kryo</code>， 而maven选择了其中版本更高的那个。</p>]]></content>
      
      
      <categories>
          
          <category> spark-sql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 踩坑记录 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/05/23/hello-world/"/>
      <url>/2022/05/23/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy --message <span class="string">&quot;add fuck-sparksql.md&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
